{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding GraphRAG output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For this analysis, we will be looking at the output files generated from a previous run of GraphRAG indexing. If you want to use data from your own run, please update the \"output_path\" and \"output_subfolder\" variables accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "output_subfolder = \"20240812-215728\"\n",
    "\n",
    "analysis_path = f\"./../analysis/{output_subfolder}\"\n",
    "output_path = f\"./../sample-output/output/{output_subfolder}/artifacts\"\n",
    "base_documents_path = f\"{output_path}/create_base_documents.parquet\"\n",
    "base_text_units_path = f\"{output_path}/create_base_text_units.parquet\"\n",
    "base_extracted_entities_path = f\"{output_path}/create_base_extracted_entities.parquet\"\n",
    "base_entity_graph_path = f\"{output_path}/create_base_entity_graph.parquet\"\n",
    "\n",
    "final_documents_path = f\"{output_path}/create_final_documents.parquet\"\n",
    "final_text_units_path = f\"{output_path}/create_final_text_units.parquet\"\n",
    "final_entities_path = f\"{output_path}/create_final_entities.parquet\"\n",
    "final_nodes_path = f\"{output_path}/create_final_nodes.parquet\"\n",
    "final_relationships_path = f\"{output_path}/create_final_relationships.parquet\"\n",
    "final_covariates_path = f\"{output_path}/create_final_covariates.parquet\"\n",
    "\n",
    "final_communities_path = f\"{output_path}/create_final_communities.parquet\"\n",
    "final_community_reports_path = f\"{output_path}/create_final_community_reports.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the base document\n",
    "df_base_documents = pd.read_parquet(base_documents_path)\n",
    "df_base_documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how many text units are created\n",
    "text_units_list = df_base_documents.loc[0, 'text_units']\n",
    "print(f\"Total count of text units: {len(text_units_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the text units\n",
    "df_base_text_units_path = pd.read_parquet(base_text_units_path)\n",
    "df_base_text_units_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at the entities extracted from the text units\n",
    "df_base_extracted_entities_path = pd.read_parquet(base_extracted_entities_path)\n",
    "df_base_extracted_entities_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting, the entities are saved using graphML file format. Let's extract it as save as XML file so that we can have a look at it.\n",
    "base_extracted_entities = df_base_extracted_entities_path[\"entity_graph\"]\n",
    "\n",
    "base_extracted_entities = base_extracted_entities[0]\n",
    "try:\n",
    "    os.makedirs(analysis_path, exist_ok=True)\n",
    "    print(f\"Directory '{analysis_path}' created successfully or already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating directory '{analysis_path}': {e}\")\n",
    "\n",
    "with open(f\"{analysis_path}/base_extracted_entities.xml\", \"w\") as f:\n",
    "    f.write(base_extracted_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at the base entity graph file created\n",
    "df_base_entity_graph_path = pd.read_parquet(base_entity_graph_path)\n",
    "df_base_entity_graph_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting, the base entities are saved using graphML file format. Let's extract it as save as XML file so that we can have a look at it.\n",
    "base_entity_graph = df_base_entity_graph_path[\"clustered_graph\"]\n",
    "\n",
    "#base_extracted_entity_graph = base_entity_graph[0]\n",
    "\n",
    "for index, value in base_entity_graph.items():\n",
    "    with open(f\"{analysis_path}/base_entity_graph_cg{index}.xml\", \"w\") as f:\n",
    "        f.write(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the base entity graph, the list of multiple descriptions are combined to a single description.\n",
    "# Now, let's look at the final documents\n",
    "df_final_documents = pd.read_parquet(final_documents_path)\n",
    "df_final_documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking final entities\n",
    "df_final_entities = pd.read_parquet(final_entities_path)\n",
    "df_final_entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking final relationships\n",
    "df_final_relationships = pd.read_parquet(final_relationships_path)\n",
    "df_final_relationships.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Final text units\n",
    "df_final_text_units = pd.read_parquet(final_text_units_path)\n",
    "df_final_text_units.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice, but what are the Covariates anyway? Let's look at it\n",
    "df_final_covariates = pd.read_parquet(final_covariates_path)\n",
    "df_final_covariates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally, let's look at the communities and community reports\n",
    "df_final_communities = pd.read_parquet(final_communities_path)\n",
    "df_final_communities.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_community_reports = pd.read_parquet(final_community_reports_path)\n",
    "df_final_community_reports.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
